model_conf:
  input_dim: 80
  output_dim: 5538
  cmvn_file: /Work21/2020/songtongtong/wenet/pre-trained/wenetspeech_20220506_u2pp_conformer_exp/global_cmvn
  is_json_cmvn: true
  decoder_type: bitransformer
  decoder_conf:
    attention_heads: 8
    dropout_rate: 0.1
    linear_units: 2048
    num_blocks: 3
    positional_dropout_rate: 0.1
    r_num_blocks: 3
    self_attention_dropout_rate: 0.1
    src_attention_dropout_rate: 0.1
  encoder_type: conformer
  encoder_conf:
    activation_type: swish
    attention_dropout_rate: 0.1
    attention_heads: 8
    causal: true
    cnn_module_kernel: 15
    cnn_module_norm: layer_norm
    dropout_rate: 0.1
    input_layer: conv2d
    linear_units: 2048
    normalize_before: true
    num_blocks: 12
    output_size: 512
    pos_enc_layer_type: rel_pos
    positional_dropout_rate: 0.1
    selfattention_layer_type: rel_selfattn
    use_cnn_module: true
    use_dynamic_chunk: false
    use_dynamic_left_chunk: false
  model_conf:
    ctc_weight: 0.3
    length_normalized_loss: false
    lsm_weight: 0.1
    reverse_weight: 0.3
  
# feature extraction
collate_conf:
  normalization: false
  # spec level config
  feature_extraction_conf:
      resample_rate: 16000
      wav_dither: 0.0
      mel_bins: 80
  feature_dither: 0.0 # add dither [-feature_dither,feature_dither] on fbank feature
  spec_aug: true
  spec_aug_conf:
      num_t_mask: 3
      num_f_mask: 2
      max_t: 50
      max_f: 10

# dataset related
dataset_conf:
    max_length: 2000
    min_length: 10
    batch_type: 'dynamic' # dynamic or static
    max_frames_in_batch: 10000 # if dynamic
    batch_size: 1 # if static
    sort: true
    raw_wav: true

grad_clip: 5
accum_grad: 1
max_epoch: 50
log_interval: 100

optim: adam
optim_conf:
    lr: 0.001
scheduler: warmuplr     # pytorch v1.1.0+ required
scheduler_conf:
    warmup_steps: 25000