model_conf:
  input_dim: 80
  output_dim: 5002
  is_json_cmvn: true
  cmvn_file: ../../pre-trained/librispeech_20210610_u2pp_conformer_exp/global_cmvn

  encoder_use_adapter: true
  decoder_use_adapter: true
  down_size: 64
  scalar: 0.1 # learnable, 0.1-1
  
  decoder: bitransformer
  decoder_conf:
    attention_heads: 4
    dropout_rate: 0.1
    linear_units: 2048
    num_blocks: 3
    positional_dropout_rate: 0.1
    r_num_blocks: 3
    self_attention_dropout_rate: 0.1
    src_attention_dropout_rate: 0.1
  encoder: conformer
  encoder_conf:
    activation_type: swish
    attention_dropout_rate: 0.1
    attention_heads: 4
    causal: true
    cnn_module_kernel: 15
    cnn_module_norm: layer_norm
    dropout_rate: 0.1
    input_layer: conv2d
    linear_units: 2048
    normalize_before: true
    num_blocks: 12
    output_size: 256
    pos_enc_layer_type: rel_pos
    positional_dropout_rate: 0.1
    selfattention_layer_type: rel_selfattn
    use_cnn_module: true
    use_dynamic_chunk: true
    use_dynamic_left_chunk: false
  model_conf:
    ctc_weight: 0.3
    length_normalized_loss: false
    lsm_weight: 0.1
    reverse_weight: 0.3

# feature extraction
collate_conf:
    # spec level config
    feature_extraction_conf:
        resample_rate: 16000
        # online speed perturb conf
        speed_perturb_rate: 0 # must be 0 if kaldi
        speeds: [0.9, 1.1, 0.1] # [start, end, interval]
        wav_dither: 0.0
        mel_bins: 80
    feature_dither: 0.0 # add dither [-feature_dither,feature_dither] on fbank feature
    spec_sub: false
    spec_sub_conf:
        num_t_sub: 3
        max_t: 30
    spec_aug: true
    spec_aug_conf:
        num_t_mask: 3
        num_f_mask: 2
        max_t: 50
        max_f: 10
  
# dataset related
dataset_conf:
    # offline speed perturb conf
    speed_perturb: False
    speeds: [0.9, 1.1, 0.1]
    max_length: 2000
    min_length: 10
    batch_type: 'dynamic' # dynamic or static, shuffle
    max_frames_in_batch: 10000 # if dynamic
    batch_size: 12 # if staticd
    sort: true
    raw_wav: true # must be false if kaldi else true

grad_clip: 5
accum_grad: 1
max_epoch: 100
log_interval: 100

optim: adam
optim_conf:
    lr: 0.001
scheduler: warmuplr     # pytorch v1.1.0+ required
warmup_epoch: 10

