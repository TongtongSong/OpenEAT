# network architecture
model_conf:
    d_model: 256  # dimension of attention
    attention_heads: 4
    linear_units: 1024  # the number of units of position-wise feed forward
    dropout_rate: 0.1
    length_normalized_loss: false
    # encoder related
    input_layer: 'conv2d'
    pos_enc_layer_type: 'rel_pos' # rel_pos is for conformer
    encoder_num_blocks: 12   # the number of encoder blocks

    # conformer config
    macaron_style: true # true is for conformer
    use_cnn_module: true # true is for conformer
    cnn_module_kernel: 15
    
    # adapter config
    encoder_use_adapter: false
    decoder_use_adapter: false
    down_size: 64
    scalar: "0.1" # learnable, 0.1-1

    #AED config
    ctc_weight: 0.3
    lsm_weight: 0.1
    decoder_num_blocks: 3

    # bidecoder config
    r_decoder_num_blocks: 3
    reverse_weight: 0.3

# feature extraction
collate_conf:
    # spec level config
    feature_extraction_conf:
        resample_rate: 16000
        speed_perturb_rate: 0
        speeds: [0.9, 1.1, 0.1] # [start, end, interval]
        wav_dither: 0.0
        mel_bins: 80
    feature_dither: 0.0 # add dither [-feature_dither,feature_dither] on fbank feature
    spec_sub: false
    spec_sub_conf:
        num_t_sub: 3
        max_t: 30
    spec_aug: true
    spec_aug_conf:
        num_t_mask: 3
        num_f_mask: 2
        max_t: 50
        max_f: 10

# dataset related
dataset_conf:
    speed_perturb: False
    speeds: [0.9, 1.1, 0.1]
    max_length: 2000
    min_length: 10
    batch_type: 'dynamic' # dynamic or static, shuffle
    max_frames_in_batch: 10000 # if dynamic
    batch_size: 12 # if staticd
    sort: true
    raw_wav: true

grad_clip: 5
accum_grad: 1
max_epoch: 100
log_interval: 100

optim: adam
optim_conf:
    lr: 0.001
scheduler: warmuplr     # pytorch v1.1.0+ required
warmup_epoch: 10
